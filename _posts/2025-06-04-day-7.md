---
layout: post
title: "Day 1 â€“ Meta-adv Walkthrough"
date: 2025-06-04
author: Tyrell Adams
permalink: /day7.html
tags: ["Mahine Learning", "Python", "AI"]

what_i_learned: |
  Today we went into more detail about meta-adv and about the overal process of how to train an AI on ow to handle new,       unforeseen attacks. We are basically teaching AI to defend itself by showing it examples of adversarial attacks or "Sneaky tricks" that causes AI to make mistakes. The Mmodel-agnostic meta-learning finds the best starting point to ensure the model can adapt fast to new problems with little to no training. The examples of adversarial attacks, come from images from CIFAR-10 and Tiny-ImageNet which are collections of images within a dataset that helps train and test ai.
blockers: |
  During the small ML project, initialy I had trouble figuring out the meaning of te codes and why they did what they did.

reflection: |
  I gained a better nderstanding of the machine learning example that we been going over and how pictures is used to train the model. I also dove deeper into key terms like loss functions and gradients for example. Loss function being how far off the model's predictions are from the correct answer and gradients being another way of saying "rate of change." Then the machine learning project showed me another example of what the code should look like. I just need to take the time to go over and understand the code.
---
